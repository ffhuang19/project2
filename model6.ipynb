{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dc99936-c120-42fe-9c86-12515a4baed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/courseml/lib/python3.10/site-packages/albumentations/check_version.py:147: UserWarning: Error fetching version info <urlopen error _ssl.c:1000: The handshake operation timed out>\n",
      "  data = fetch_version_info()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15b29138",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './training/' \n",
    "\n",
    "IMAGE_DIR = os.path.join(DATA_DIR, 'images')\n",
    "MASK_DIR = os.path.join(DATA_DIR, 'groundtruth')\n",
    "\n",
    "# --- New settings for Patch-based Classification ---\n",
    "DEVICE = 'cpu'\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 64 # We can use a larger batch size now\n",
    "LEARNING_RATE = 0.001\n",
    "PATCH_SIZE = 16\n",
    "FOREGROUND_THRESHOLD = 0.25 # From the project description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cef7059c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_augmentations():\n",
    "    \"\"\"\n",
    "    Returns a set of heavy augmentations for the training data.\n",
    "    \"\"\"\n",
    "    return A.Compose([\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.2),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "def get_validation_augmentations():\n",
    "    \"\"\"Returns minimal augmentations for validation (no resizing).\"\"\"\n",
    "    return A.Compose([\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6caa2e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Helper function to label a mask patch ---\n",
    "def patch_to_label(patch, threshold):\n",
    "    \"\"\"\n",
    "    Assigns a label (1 for road, 0 for background) to a mask patch\n",
    "    based on the percentage of foreground pixels.\n",
    "    \"\"\"\n",
    "    # Ground truth masks have values of 0 or 255.\n",
    "    # We calculate the mean and normalize to a 0-1 range.\n",
    "    foreground_percentage = np.mean(patch) / 255.0\n",
    "    return 1 if foreground_percentage > threshold else 0\n",
    "\n",
    "# --- New Dataset for 16x16 Patches ---\n",
    "class PatchDataset(Dataset):\n",
    "    def __init__(self, image_paths, mask_paths, augmentations=None):\n",
    "        self.augmentations = augmentations\n",
    "        self.patches = []\n",
    "\n",
    "        print(\"Creating patches... This might take a moment.\")\n",
    "        # Iterate through images and create patches\n",
    "        for img_path, mask_path in tqdm(zip(image_paths, mask_paths), total=len(image_paths)):\n",
    "            image = cv2.imread(img_path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            img_h, img_w, _ = image.shape\n",
    "            \n",
    "            for y in range(0, img_h, PATCH_SIZE):\n",
    "                for x in range(0, img_w, PATCH_SIZE):\n",
    "                    # Ensure the patch is fully within the image bounds\n",
    "                    if y + PATCH_SIZE > img_h or x + PATCH_SIZE > img_w:\n",
    "                        continue\n",
    "                        \n",
    "                    image_patch = image[y:y+PATCH_SIZE, x:x+PATCH_SIZE]\n",
    "                    mask_patch = mask[y:y+PATCH_SIZE, x:x+PATCH_SIZE]\n",
    "                    \n",
    "                    label = patch_to_label(mask_patch, FOREGROUND_THRESHOLD)\n",
    "                    \n",
    "                    self.patches.append((image_patch, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.patches)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_patch, label = self.patches[idx]\n",
    "        \n",
    "        if self.augmentations:\n",
    "            augmented = self.augmentations(image=image_patch)\n",
    "            image_patch = augmented['image']\n",
    "            \n",
    "        # Return the patch and its label as a tensor\n",
    "        return image_patch, torch.tensor([label], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bead762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- New CNN Model for Patch Classification ---\n",
    "class PatchClassifier(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_features=1):\n",
    "        super(PatchClassifier, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            # Input: 3 x 16 x 16\n",
    "            nn.Conv2d(in_channels, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # -> 32 x 8 x 8\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # -> 64 x 4 x 4\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # -> 128 x 2 x 2\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 2 * 2, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, out_features),\n",
    "            nn.Sigmoid() # To output a probability (0 to 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "# --- New F1 Score for Classification ---\n",
    "def f1_score_classification(outputs, labels, threshold=0.5):\n",
    "    # Convert model outputs (probabilities) to binary predictions (0 or 1)\n",
    "    preds = (outputs > threshold).float()\n",
    "    \n",
    "    tp = (preds * labels).sum()\n",
    "    fp = (preds * (1 - labels)).sum()\n",
    "    fn = ((1 - preds) * labels).sum()\n",
    "    \n",
    "    precision = tp / (tp + fp + 1e-6)\n",
    "    recall = tp / (tp + fn + 1e-6)\n",
    "    \n",
    "    f1 = 2 * (precision * recall) / (precision + recall + 1e-6)\n",
    "    return f1.item()\n",
    "\n",
    "\n",
    "# --- Model, Loss, and Optimizer Setup ---\n",
    "model = PatchClassifier().to(DEVICE)\n",
    "loss_fn = nn.BCELoss() # Binary Cross Entropy Loss for classification\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0692cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating patches... This might take a moment.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:00<00:00, 185.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating patches... This might take a moment.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 185.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Created 50000 training patches and 12500 validation patches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Data Splitting and DataLoader Setup ---\n",
    "all_image_ids = sorted(os.listdir(IMAGE_DIR))\n",
    "random.seed(42)\n",
    "random.shuffle(all_image_ids)\n",
    "\n",
    "# Split into train and validation sets (80/20)\n",
    "train_size = int(0.8 * len(all_image_ids))\n",
    "train_ids = all_image_ids[:train_size]\n",
    "valid_ids = all_image_ids[train_size:]\n",
    "\n",
    "# Create lists of full file paths for the datasets\n",
    "train_image_paths = [os.path.join(IMAGE_DIR, img_id) for img_id in train_ids]\n",
    "train_mask_paths = [os.path.join(MASK_DIR, img_id) for img_id in train_ids]\n",
    "\n",
    "valid_image_paths = [os.path.join(IMAGE_DIR, img_id) for img_id in valid_ids]\n",
    "valid_mask_paths = [os.path.join(MASK_DIR, img_id) for img_id in valid_ids]\n",
    "\n",
    "# Create Dataset and DataLoader instances\n",
    "train_dataset = PatchDataset(train_image_paths, train_mask_paths, augmentations=get_training_augmentations())\n",
    "valid_dataset = PatchDataset(valid_image_paths, valid_mask_paths, augmentations=get_validation_augmentations())\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"\\nCreated {len(train_dataset)} training patches and {len(valid_dataset)} validation patches.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9a31831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -> Loss: 0.4891, F1-Score: 0.3338\n",
      "Valid -> Loss: 0.4381, F1-Score: 0.4234\n",
      "Model saved! Best Validation F1-Score: 0.4234\n",
      "\n",
      "Epoch: 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -> Loss: 0.4182, F1-Score: 0.5793\n",
      "Valid -> Loss: 0.4146, F1-Score: 0.4517\n",
      "Model saved! Best Validation F1-Score: 0.4517\n",
      "\n",
      "Epoch: 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -> Loss: 0.4014, F1-Score: 0.6094\n",
      "Valid -> Loss: 0.4275, F1-Score: 0.5179\n",
      "Model saved! Best Validation F1-Score: 0.5179\n",
      "\n",
      "Epoch: 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -> Loss: 0.3885, F1-Score: 0.6216\n",
      "Valid -> Loss: 0.4031, F1-Score: 0.4759\n",
      "\n",
      "Epoch: 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -> Loss: 0.3814, F1-Score: 0.6288\n",
      "Valid -> Loss: 0.4072, F1-Score: 0.5095\n",
      "\n",
      "Epoch: 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -> Loss: 0.3736, F1-Score: 0.6417\n",
      "Valid -> Loss: 0.3867, F1-Score: 0.5453\n",
      "Model saved! Best Validation F1-Score: 0.5453\n",
      "\n",
      "Epoch: 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -> Loss: 0.3673, F1-Score: 0.6453\n",
      "Valid -> Loss: 0.3837, F1-Score: 0.5324\n",
      "\n",
      "Epoch: 8/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -> Loss: 0.3614, F1-Score: 0.6515\n",
      "Valid -> Loss: 0.3822, F1-Score: 0.5461\n",
      "Model saved! Best Validation F1-Score: 0.5461\n",
      "\n",
      "Epoch: 9/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -> Loss: 0.3542, F1-Score: 0.6629\n",
      "Valid -> Loss: 0.3905, F1-Score: 0.5055\n",
      "\n",
      "Epoch: 10/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -> Loss: 0.3522, F1-Score: 0.6613\n",
      "Valid -> Loss: 0.3788, F1-Score: 0.5374\n",
      "\n",
      "Epoch: 11/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -> Loss: 0.3478, F1-Score: 0.6701\n",
      "Valid -> Loss: 0.3757, F1-Score: 0.5333\n",
      "\n",
      "Epoch: 12/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -> Loss: 0.3435, F1-Score: 0.6764\n",
      "Valid -> Loss: 0.3736, F1-Score: 0.5375\n",
      "\n",
      "Epoch: 13/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -> Loss: 0.3357, F1-Score: 0.6800\n",
      "Valid -> Loss: 0.3723, F1-Score: 0.5297\n",
      "\n",
      "Epoch: 14/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -> Loss: 0.3336, F1-Score: 0.6857\n",
      "Valid -> Loss: 0.3797, F1-Score: 0.5380\n",
      "\n",
      "Epoch: 15/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -> Loss: 0.3287, F1-Score: 0.6891\n",
      "Valid -> Loss: 0.3839, F1-Score: 0.5276\n",
      "\n",
      "Epoch: 16/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -> Loss: 0.3237, F1-Score: 0.6928\n",
      "Valid -> Loss: 0.3870, F1-Score: 0.5435\n",
      "\n",
      "Epoch: 17/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -> Loss: 0.3247, F1-Score: 0.6970\n",
      "Valid -> Loss: 0.3947, F1-Score: 0.5066\n",
      "\n",
      "Epoch: 18/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -> Loss: 0.3204, F1-Score: 0.6992\n",
      "Valid -> Loss: 0.3681, F1-Score: 0.5293\n",
      "\n",
      "Epoch: 19/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -> Loss: 0.3180, F1-Score: 0.7010\n",
      "Valid -> Loss: 0.3775, F1-Score: 0.5243\n",
      "\n",
      "Epoch: 20/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -> Loss: 0.3155, F1-Score: 0.7020\n",
      "Valid -> Loss: 0.3688, F1-Score: 0.5395\n",
      "\n",
      "Epoch: 21/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -> Loss: 0.3092, F1-Score: 0.7033\n",
      "Valid -> Loss: 0.3592, F1-Score: 0.5225\n",
      "\n",
      "Epoch: 22/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -> Loss: 0.3094, F1-Score: 0.7101\n",
      "Valid -> Loss: 0.3898, F1-Score: 0.5281\n",
      "\n",
      "Epoch: 23/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -> Loss: 0.3085, F1-Score: 0.7100\n",
      "Valid -> Loss: 0.3661, F1-Score: 0.5294\n",
      "\n",
      "Epoch: 24/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -> Loss: 0.3047, F1-Score: 0.7122\n",
      "Valid -> Loss: 0.3837, F1-Score: 0.5690\n",
      "Model saved! Best Validation F1-Score: 0.5690\n",
      "\n",
      "Epoch: 25/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -> Loss: 0.3031, F1-Score: 0.7160\n",
      "Valid -> Loss: 0.3935, F1-Score: 0.5195\n",
      "\n",
      "Epoch: 26/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -> Loss: 0.2967, F1-Score: 0.7239\n",
      "Valid -> Loss: 0.3781, F1-Score: 0.5456\n",
      "\n",
      "Epoch: 27/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -> Loss: 0.2959, F1-Score: 0.7255\n",
      "Valid -> Loss: 0.3716, F1-Score: 0.5462\n",
      "\n",
      "Epoch: 28/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -> Loss: 0.2962, F1-Score: 0.7240\n",
      "Valid -> Loss: 0.3735, F1-Score: 0.5532\n",
      "\n",
      "Epoch: 29/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -> Loss: 0.2902, F1-Score: 0.7328\n",
      "Valid -> Loss: 0.3810, F1-Score: 0.5401\n",
      "\n",
      "Epoch: 30/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -> Loss: 0.2887, F1-Score: 0.7294\n",
      "Valid -> Loss: 0.3617, F1-Score: 0.5307\n",
      "\n",
      "Epoch: 31/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -> Loss: 0.2881, F1-Score: 0.7324\n",
      "Valid -> Loss: 0.3898, F1-Score: 0.5501\n",
      "\n",
      "Epoch: 32/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -> Loss: 0.2850, F1-Score: 0.7361\n",
      "Valid -> Loss: 0.3739, F1-Score: 0.5492\n",
      "\n",
      "Epoch: 33/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -> Loss: 0.2847, F1-Score: 0.7374\n",
      "Valid -> Loss: 0.4157, F1-Score: 0.5387\n",
      "\n",
      "Epoch: 34/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -> Loss: 0.2812, F1-Score: 0.7398\n",
      "Valid -> Loss: 0.3717, F1-Score: 0.5603\n",
      "\n",
      "Epoch: 35/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -> Loss: 0.2792, F1-Score: 0.7426\n",
      "Valid -> Loss: 0.3755, F1-Score: 0.5109\n",
      "\n",
      "Epoch: 36/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -> Loss: 0.2746, F1-Score: 0.7472\n",
      "Valid -> Loss: 0.3984, F1-Score: 0.5558\n",
      "\n",
      "Epoch: 37/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -> Loss: 0.2720, F1-Score: 0.7508\n",
      "Valid -> Loss: 0.3900, F1-Score: 0.5521\n",
      "\n",
      "Epoch: 38/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -> Loss: 0.2750, F1-Score: 0.7432\n",
      "Valid -> Loss: 0.3715, F1-Score: 0.5590\n",
      "\n",
      "Epoch: 39/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -> Loss: 0.2690, F1-Score: 0.7536\n",
      "Valid -> Loss: 0.3833, F1-Score: 0.5622\n",
      "\n",
      "Epoch: 40/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -> Loss: 0.2693, F1-Score: 0.7530\n",
      "Valid -> Loss: 0.3818, F1-Score: 0.5425\n",
      "\n",
      "Epoch: 41/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -> Loss: 0.2680, F1-Score: 0.7541\n",
      "Valid -> Loss: 0.3790, F1-Score: 0.5550\n",
      "\n",
      "Epoch: 42/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -> Loss: 0.2665, F1-Score: 0.7591\n",
      "Valid -> Loss: 0.3787, F1-Score: 0.5374\n",
      "\n",
      "Epoch: 43/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -> Loss: 0.2617, F1-Score: 0.7645\n",
      "Valid -> Loss: 0.3881, F1-Score: 0.5405\n",
      "\n",
      "Epoch: 44/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -> Loss: 0.2590, F1-Score: 0.7635\n",
      "Valid -> Loss: 0.4203, F1-Score: 0.5677\n",
      "\n",
      "Epoch: 45/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -> Loss: 0.2587, F1-Score: 0.7650\n",
      "Valid -> Loss: 0.4167, F1-Score: 0.5643\n",
      "\n",
      "Epoch: 46/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -> Loss: 0.2562, F1-Score: 0.7666\n",
      "Valid -> Loss: 0.4405, F1-Score: 0.5570\n",
      "\n",
      "Epoch: 47/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -> Loss: 0.2542, F1-Score: 0.7687\n",
      "Valid -> Loss: 0.3963, F1-Score: 0.5339\n",
      "\n",
      "Epoch: 48/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -> Loss: 0.2583, F1-Score: 0.7649\n",
      "Valid -> Loss: 0.3987, F1-Score: 0.5506\n",
      "\n",
      "Epoch: 49/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -> Loss: 0.2539, F1-Score: 0.7675\n",
      "Valid -> Loss: 0.3854, F1-Score: 0.5521\n",
      "\n",
      "Epoch: 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -> Loss: 0.2515, F1-Score: 0.7729\n",
      "Valid -> Loss: 0.3987, F1-Score: 0.5583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# --- PyTorch Training and Validation Loop ---\n",
    "\n",
    "max_fscore = 0\n",
    "best_model_path = 'best_model.pth'\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'\\nEpoch: {epoch + 1}/{EPOCHS}')\n",
    "    \n",
    "    # --- Training Phase ---\n",
    "    model.train()\n",
    "    train_loss, train_fscore, train_correct = 0, 0, 0\n",
    "    train_pbar = tqdm(train_loader, desc=f\"Training\", leave=False)\n",
    "    \n",
    "    for patches, labels in train_pbar:\n",
    "        patches, labels = patches.to(DEVICE), labels.to(DEVICE)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(patches)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate metrics\n",
    "        train_loss += loss.item()\n",
    "        f1 = f1_score_classification(outputs, labels)\n",
    "        train_fscore += f1\n",
    "        \n",
    "        # Update progress bar\n",
    "        train_pbar.set_postfix(loss=loss.item(), f1=f1)\n",
    "    \n",
    "    # --- Validation Phase ---\n",
    "    model.eval()\n",
    "    val_loss, val_fscore = 0, 0\n",
    "    with torch.no_grad():\n",
    "        val_pbar = tqdm(valid_loader, desc=f\"Validation\", leave=False)\n",
    "        for patches, labels in val_pbar:\n",
    "            patches, labels = patches.to(DEVICE), labels.to(DEVICE)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(patches)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            \n",
    "            # Accumulate metrics\n",
    "            val_loss += loss.item()\n",
    "            f1 = f1_score_classification(outputs, labels)\n",
    "            val_fscore += f1\n",
    "            \n",
    "            # Update progress bar\n",
    "            val_pbar.set_postfix(loss=loss.item(), f1=f1)\n",
    "\n",
    "    # --- Logging and Model Saving ---\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    avg_train_fscore = train_fscore / len(train_loader)\n",
    "    \n",
    "    avg_val_loss = val_loss / len(valid_loader)\n",
    "    avg_val_fscore = val_fscore / len(valid_loader)\n",
    "    \n",
    "    print(f\"Train -> Loss: {avg_train_loss:.4f}, F1-Score: {avg_train_fscore:.4f}\")\n",
    "    print(f\"Valid -> Loss: {avg_val_loss:.4f}, F1-Score: {avg_val_fscore:.4f}\")\n",
    "    \n",
    "    # Save the model if it has the best validation F1-score so far\n",
    "    if avg_val_fscore > max_fscore:\n",
    "        max_fscore = avg_val_fscore\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"Model saved! Best Validation F1-Score: {max_fscore:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ae082d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading best patch classifier model for prediction...\n",
      "Model loaded.\n",
      "Found 50 test images. Generating submission file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:14<00:00,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Submission file 'submission.csv' created successfully! ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Final Prediction and Submission ---\n",
    "import re\n",
    "\n",
    "TEST_IMAGE_DIR = './test_set_images/'\n",
    "SUBMISSION_FILENAME = 'submission.csv'\n",
    "\n",
    "# Load the best trained model\n",
    "print(\"\\nLoading best patch classifier model for prediction...\")\n",
    "best_model = PatchClassifier().to(DEVICE)\n",
    "best_model.load_state_dict(torch.load('best_model.pth'))\n",
    "best_model.eval()\n",
    "print(\"Model loaded.\")\n",
    "\n",
    "# Get augmentations for test data\n",
    "test_augmentations = get_validation_augmentations()\n",
    "\n",
    "# Collect all test image file paths\n",
    "test_image_paths = []\n",
    "for root, _, files in os.walk(TEST_IMAGE_DIR):\n",
    "    for file in files:\n",
    "        if file.endswith(\".png\"):\n",
    "            test_image_paths.append(os.path.join(root, file))\n",
    "test_image_paths.sort()\n",
    "\n",
    "print(f\"Found {len(test_image_paths)} test images. Generating submission file...\")\n",
    "with open(SUBMISSION_FILENAME, \"w\") as f:\n",
    "    f.write(\"id,prediction\\n\")\n",
    "    \n",
    "    for img_path in tqdm(test_image_paths):\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        img_h, img_w, _ = image.shape\n",
    "        img_id_str = os.path.basename(img_path)\n",
    "        img_number = int(re.search(r\"(\\d+)\", img_id_str).group(1))\n",
    "        \n",
    "        for y in range(0, img_h, PATCH_SIZE):\n",
    "            for x in range(0, img_w, PATCH_SIZE):\n",
    "                if y + PATCH_SIZE > img_h or x + PATCH_SIZE > img_w:\n",
    "                    continue\n",
    "                \n",
    "                image_patch = image[y:y+PATCH_SIZE, x:x+PATCH_SIZE]\n",
    "                \n",
    "                # Apply transformations\n",
    "                augmented = test_augmentations(image=image_patch)\n",
    "                input_tensor = augmented['image'].unsqueeze(0).to(DEVICE)\n",
    "\n",
    "                # Predict with the model\n",
    "                with torch.no_grad():\n",
    "                    output = best_model(input_tensor)\n",
    "                    prediction = 1 if output.item() > 0.5 else 0\n",
    "                \n",
    "                # Write to submission file\n",
    "                submission_id = \"{:03d}_{}_{}\".format(img_number, x, y)\n",
    "                f.write(f\"{submission_id},{prediction}\\n\")\n",
    "\n",
    "print(f\"\\n--- Submission file '{SUBMISSION_FILENAME}' created successfully! ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443a7757",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "courseml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
